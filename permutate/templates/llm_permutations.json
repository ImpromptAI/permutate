[
  {
    "provider": "OpenAIChat",
    "model_name": "gpt-3.5-turbo",
    "supported_max_tokens": 4096,
    "temperature": 0,
    "max_tokens": 1024,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
    "n": 1,
    "best_of": 1
  },
  {
    "provider": "OpenAIChat",
    "model_name": "gpt-3.5-turbo-16k",
    "supported_max_tokens": 16384,
    "temperature": 0,
    "max_tokens": 1024,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
    "n": 1,
    "best_of": 1
  },
  {
    "provider": "OpenAIChat",
    "model_name": "gpt-3.5-turbo-0613",
    "supported_max_tokens": 4096,
    "temperature": 0,
    "max_tokens": 1024,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
    "n": 1,
    "best_of": 1
  },
  {
    "provider": "OpenAIChat",
    "model_name": "gpt-3.5-turbo-16k-0613",
    "supported_max_tokens": 16384,
    "temperature": 0,
    "max_tokens": 1024,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
    "n": 1,
    "best_of": 1
  },
  {
    "provider": "OpenAIChat",
    "model_name": "gpt-4",
    "supported_max_tokens": 8192,
    "temperature": 0,
    "max_tokens": 1024,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
    "n": 1,
    "best_of": 1
  },
  {
    "provider": "OpenAIChat",
    "model_name": "gpt-4-0613",
    "supported_max_tokens": 8192,
    "temperature": 0,
    "max_tokens": 1024,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
    "n": 1,
    "best_of": 1
  },
  {
    "provider": "OpenAIChat",
    "model_name": "gpt-4-32k",
    "supported_max_tokens": 32768,
    "temperature": 0,
    "max_tokens": 1024,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
    "n": 1,
    "best_of": 1
  },
  {
    "provider": "OpenAIChat",
    "model_name": "gpt-4-32k-0613",
    "supported_max_tokens": 32768,
    "temperature": 0,
    "max_tokens": 1024,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
    "n": 1,
    "best_of": 1
  },
  {
    "provider": "Cohere",
    "model_name": "command",
    "temperature": 0,
    "max_tokens": 1024,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
    "n": 1,
    "best_of": 1
  },
  {
    "provider": "Cohere",
    "model_name": "command-light",
    "temperature": 0,
    "max_tokens": 1024,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
    "n": 1,
    "best_of": 1
  },
  {
    "provider": "Cohere",
    "model_name": "command-nightly",
    "temperature": 0,
    "max_tokens": 1024,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
    "n": 1,
    "best_of": 1
  },
  {
    "provider": "Cohere",
    "model_name": "command-light-nightly",
    "temperature": 0,
    "max_tokens": 1024,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
    "n": 1,
    "best_of": 1
  },
  {
    "provider": "GooglePalm2",
    "temperature": 0,
    "max_tokens": 1024,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0,
    "n": 1,
    "best_of": 1
  }
]